{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import torch \n",
    "from utils import _load_vocab\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import librosa\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import librosa.display\n",
    "import ast \n",
    "from sampler import edit_distance\n",
    "from abc import ABC,abstractmethod\n",
    "\n",
    "\n",
    "VOCAB_DICT=_load_vocab()\n",
    "\n",
    "# Dataloader class\n",
    "class MultiViewDataset(Dataset,ABC):\n",
    "    def __init__(self, csv_file,max_mfcc_len,n_mfcc=13):\n",
    "        self.data=pd.read_csv(csv_file)\n",
    "        self.dir_path=os.path.dirname(csv_file)\n",
    "        self.vocab_dict=VOCAB_DICT\n",
    "        self.n_mfcc=n_mfcc\n",
    "        self.max_mfcc_len=max_mfcc_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def char_to_idx(self, transcript):\n",
    "        one_hot = torch.zeros(len(transcript), len(self.vocab_dict))\n",
    "        for i, char in enumerate(transcript):\n",
    "            one_hot[i, self.vocab_dict[char]] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def compute_mfcc(self, audio_path):\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        n_fft = min(2048, len(y))\n",
    "        hop_length = n_fft // 4\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, \n",
    "                                     n_mfcc=self.n_mfcc, \n",
    "                                     n_fft=n_fft, \n",
    "                                     hop_length=hop_length)\n",
    "\n",
    "        width = min(9, mfccs.shape[1])\n",
    "        if width < 3:\n",
    "            width = 3\n",
    "        \n",
    "        width = min(width, mfccs.shape[1])\n",
    "\n",
    "        if width % 2 == 0:\n",
    "            width -= 1\n",
    "\n",
    "        delta1 = librosa.feature.delta(mfccs, order=1, width=width)\n",
    "        delta2 = librosa.feature.delta(mfccs, order=2, width=width)\n",
    "\n",
    "        mfccs_combined = np.concatenate((mfccs, delta1, delta2), axis=0)\n",
    "        return mfccs_combined\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "class MultiViewTrainDataset(MultiViewDataset):\n",
    "    def __init__(self,csv_file,loss_fn,max_mfcc_len,n_mfcc=13):\n",
    "        super().__init__(csv_file, max_mfcc_len=max_mfcc_len,n_mfcc=n_mfcc)\n",
    "        self.loss_fn=loss_fn\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        audio_path_x1=self.data[\"audio_path\"][idx]\n",
    "        audio_path_x1=os.path.join(self.dir_path,str(audio_path_x1))\n",
    "        transcript_c1=self.data[\"transcript\"][idx]\n",
    "\n",
    "        sample_list=ast.literal_eval(self.data[\"negative_samples\"][idx])\n",
    "        \n",
    "        one_hot_c2=None\n",
    "        if 0 in self.loss_fn or 1 in self.loss_fn:\n",
    "            transcript_c2=sample_list[0]\n",
    "            one_hot_c2=self.char_to_idx(transcript_c2)\n",
    "            lev_distance=edit_distance(transcript_c1,transcript_c2)\n",
    "        \n",
    "        mfccs_x2=None\n",
    "        if 2 in self.loss_fn or 3 in self.loss_fn:\n",
    "            audio_path_x2=sample_list[1]\n",
    "            audio_path_x2=os.path.join(self.dir_path,str(audio_path_x2))\n",
    "\n",
    "            mfccs_x2=self.compute_mfcc(audio_path_x2)\n",
    "        \n",
    "        #computing mfcc\n",
    "        mfcc_x1=self.compute_mfcc(audio_path_x1) \n",
    "        \n",
    "        #computiing one hot for transcript \n",
    "        one_hot_c1=self.char_to_idx(transcript_c1)\n",
    "\n",
    "        output_tensors= [torch.tensor(mfcc_x1), one_hot_c1]\n",
    "\n",
    "        if 0 in self.loss_fn or 1 in self.loss_fn:\n",
    "            output_tensors.append(one_hot_c2)\n",
    "            output_tensors.append(lev_distance)\n",
    "    \n",
    "        if 2 in self.loss_fn or 3 in self.loss_fn:\n",
    "            output_tensors.append(torch.tensor(mfccs_x2))\n",
    "    \n",
    "        return output_tensors\n",
    "\n",
    "class MultiViewDevDataset(MultiViewDataset):\n",
    "    def __init__(self,csv_file,max_mfcc_len,n_mfcc=13):\n",
    "        super().__init__(csv_file,max_mfcc_len=max_mfcc_len,n_mfcc=n_mfcc)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        audio_path_x1=self.data[\"audio_path\"][idx]\n",
    "        audio_path_x1=os.path.join(self.dir_path,str(audio_path_x1))\n",
    "\n",
    "        #mfcc \n",
    "        audio_mfcc=self.compute_mfcc(audio_path_x1)\n",
    "\n",
    "        sample_dict=ast.literal_eval(self.data[\"sampled_words\"][idx])\n",
    "        lev_scores=[]\n",
    "        for score in sample_dict.keys():\n",
    "            for _ in range(len(sample_dict[score])):\n",
    "                lev_scores.append(score)\n",
    "\n",
    "        one_hot=[]\n",
    "        for transcripts in sample_dict.values():\n",
    "            for transcript in transcripts:\n",
    "                one_hot.append(self.char_to_idx(transcript))\n",
    "        \n",
    "        one_hot_c1=self.char_to_idx(self.data['transcript'][idx])\n",
    "\n",
    "        #sampling negative\n",
    "        one_hot_c2=self.char_to_idx(ast.literal_eval(self.data[\"negative_samples\"][idx])[0])\n",
    "        audio_path_x2=ast.literal_eval(self.data[\"negative_samples\"][idx])[1]\n",
    "        audio_path_x2=os.path.join(self.dir_path,str(audio_path_x2))\n",
    "        mfcc_x2=self.compute_mfcc(audio_path_x2)\n",
    "        \n",
    "        output_tensor=[torch.tensor(audio_mfcc),one_hot,\n",
    "                       torch.tensor(lev_scores),one_hot_c1,one_hot_c2,\n",
    "                       torch.tensor(mfcc_x2)]\n",
    "\n",
    "        return output_tensor\n",
    "\n",
    "# colate functions \n",
    "def train_collate_fn(batch,max_mfcc_len):\n",
    "\n",
    "    mfccs_x1= []\n",
    "    one_hot_c1=[]\n",
    "    one_hot_c2=[]\n",
    "    mfccs_x2=[]\n",
    "    lev_distances=[]\n",
    "\n",
    "    for item in batch:\n",
    "        mfcc_x1,oh_c1 = item[0], item[1]\n",
    "        mfccs_x1.append(mfcc_x1)\n",
    "        one_hot_c1.append(oh_c1)\n",
    "\n",
    "        if len(item) == 5:\n",
    "            oh_c2,lev_distance,mfcc_x2= item[2], item[3],item[4]\n",
    "            one_hot_c2.append(oh_c2)\n",
    "            mfccs_x2.append(mfcc_x2)\n",
    "            lev_distances.append(lev_distance)\n",
    "        elif len(item)==4:\n",
    "            if item[2].shape[1]==len(VOCAB_DICT):\n",
    "                oh_c2,lev_distance=item[2],item[3]\n",
    "                one_hot_c2.append(oh_c2)\n",
    "                lev_distances.append(lev_distance)\n",
    "        elif len(item) == 3:\n",
    "            mfcc_x2=item[2]\n",
    "            mfccs_x2.append(mfcc_x2)\n",
    "    \n",
    "    #max_mfcc_len = batch[0].dataset.max_mfcc_len\n",
    "\n",
    "    mfccs_x1=pad_mfccs(mfccs_x1,max_mfcc_len)\n",
    "    one_hot_c1=pad_sequence(one_hot_c1, batch_first=True)\n",
    "\n",
    "    result={'view1_x1':mfccs_x1,'view2_c1':one_hot_c1}\n",
    "\n",
    "    if one_hot_c2 and lev_distances:\n",
    "        one_hot_c2=pad_sequence(one_hot_c2,batch_first=True)\n",
    "        result['view2_c2']=one_hot_c2\n",
    "        result['edit_distance']=lev_distances\n",
    "\n",
    "    if mfccs_x2:\n",
    "        mfccs_x2=pad_mfccs(mfccs_x2, max_mfcc_len)\n",
    "        result['view1_x2']=mfccs_x2\n",
    "    \n",
    "    return result \n",
    "def dev_collate_fn(batch,max_mfcc_len):\n",
    "    \n",
    "    mfccs_x1=[]\n",
    "    one_hot=[]\n",
    "    lev_scores=[]\n",
    "    one_hot_c1=[]\n",
    "    one_hot_c2=[]\n",
    "    mfccs_x2=[]\n",
    "\n",
    "    for item in batch:\n",
    "        mfcc_x1,oh,lev_score,oh_c1,oh_c2,mfcc_x2=item[0],item[1],item[2],item[3],item[4],item[5]\n",
    "        mfccs_x1.append(mfcc_x1)\n",
    "        one_hot.append(oh)\n",
    "        lev_scores.append(lev_score)\n",
    "        one_hot_c1.append(oh_c1)\n",
    "        one_hot_c2.append(oh_c2)\n",
    "        mfccs_x2.append(mfcc_x2)\n",
    "    \n",
    "    #max_mfcc_len=batch[0].dataset.max_mfcc_len\n",
    "    mfccs_x1=pad_mfccs(mfccs_x1,max_mfcc_len)\n",
    "    mfccs_x2=pad_mfccs(mfccs_x2,max_mfcc_len)\n",
    "\n",
    "    one_hot=pad_batch_sequence(one_hot)\n",
    "\n",
    "    one_hot_c1=pad_sequence(one_hot_c1,batch_first=True)\n",
    "    one_hot_c2=pad_sequence(one_hot_c2,batch_first=True)\n",
    "\n",
    "    results={\"mfcc\":mfccs_x1,\n",
    "             \"sampled_one_hot\":one_hot,\n",
    "             \"lev_scores\":torch.stack(lev_scores),\n",
    "             \"ground_truth\":one_hot_c1,\n",
    "             \"one_hot_c2\":one_hot_c2,\n",
    "             \"mfcc_x2\":mfccs_x2}\n",
    "\n",
    "    return results\n",
    "\n",
    "# Padding functions\n",
    "def pad_mfccs(mfccs, max_len):\n",
    "    padded_mfccs = []\n",
    "    for mfcc in mfccs:\n",
    "        # Padding to the right with zeros\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        padded_mfcc = torch.nn.functional.pad(mfcc, (0, pad_width), 'constant', 0)\n",
    "        padded_mfccs.append(padded_mfcc)\n",
    "    return torch.stack(padded_mfccs)\n",
    "\n",
    "def pad_sequence(sequences, batch_first=False, padding_value=0):\n",
    "    return torch.nn.utils.rnn.pad_sequence(sequences, batch_first=batch_first, padding_value=padding_value)\n",
    "\n",
    "def pad_batch_sequence(batch, padding_value=0):\n",
    "    padded_batch = []\n",
    "\n",
    "    max_seq_length = max(len(seq) for sequences in batch for seq in sequences)\n",
    "    max_num_sequences = max(len(sequences) for sequences in batch)\n",
    "    \n",
    "    for sequences in batch:\n",
    "        padded_sequences = [\n",
    "            torch.nn.functional.pad(torch.tensor(seq), \n",
    "                                    (0, 0, 0, max_seq_length - len(seq)), \n",
    "                                    'constant', padding_value)\n",
    "            for seq in sequences\n",
    "        ]\n",
    "        \n",
    "        padded_sequences = pad_sequence(padded_sequences, batch_first=True, padding_value=padding_value)\n",
    "        \n",
    "        if len(padded_sequences) < max_num_sequences:\n",
    "            padding = torch.full((max_num_sequences - len(padded_sequences), \n",
    "                                  max_seq_length, \n",
    "                                  padded_sequences.shape[2]), \n",
    "                                  padding_value)\n",
    "            padded_sequences = torch.cat((padded_sequences, padding), dim=0)\n",
    "        \n",
    "        padded_batch.append(padded_sequences)\n",
    "    \n",
    "    stacked_tensor = torch.stack(padded_batch)\n",
    "\n",
    "    return stacked_tensor\n",
    "\n",
    "# loaders\n",
    "def get_train_loader(csv_file,batch_size,loss_fn,max_mfcc_len):\n",
    "\n",
    "    dataset=MultiViewTrainDataset(csv_file=csv_file,loss_fn=loss_fn,max_mfcc_len=max_mfcc_len)\n",
    "\n",
    "    loader=DataLoader(dataset, batch_size=batch_size, \n",
    "                      collate_fn=lambda batch: train_collate_fn(batch, dataset.max_mfcc_len))\n",
    "\n",
    "    return loader\n",
    "\n",
    "def get_dev_loader(csv_file,batch_size,max_mfcc_len):\n",
    "    \n",
    "    dev_dataset=MultiViewDevDataset(csv_file=csv_file,max_mfcc_len=max_mfcc_len)\n",
    "\n",
    "    dev_loader=DataLoader(dev_dataset, batch_size=batch_size, \n",
    "                          collate_fn=lambda batch: dev_collate_fn(batch, dev_dataset.max_mfcc_len))\n",
    "\n",
    "    return dev_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path='/home/ubuntu/acoustic_stuff/hindi-acoustic-word-embedding/dataset/train_aligned_dataset'\n",
    "dev_csv='sample_bhashini_dev.csv'\n",
    "train_csv='sample_bhashini_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import _load_config\n",
    "config_file=_load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=MultiViewTrainDataset(csv_file=os.path.join(root_path,train_csv),loss_fn=config_file['loss_fn'],max_mfcc_len=config_file['max_mfcc_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=[]\n",
    "for i in range(32):\n",
    "    word=dataset[i][1]\n",
    "    sequences.append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 83])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_batch_to_fixed_length(batch, max_seq_len, padding_value=0):\n",
    "   \n",
    "    padded_sequences = []\n",
    "    for seq in batch:\n",
    "        seq_len = seq.size(0)\n",
    "        padded_seq = torch.zeros(max_seq_len, seq.size(1), dtype=torch.long)\n",
    "        padded_seq[:seq_len] = seq[:seq_len]\n",
    "        padded_sequences.append(padded_seq)\n",
    "\n",
    "    padded_batch = pad_sequence(padded_sequences, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    return padded_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = [torch.cat([seq, torch.zeros(20 - seq.size(0), seq.size(1), device=seq.device)], dim=0) for seq in sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(root_path,train_csv))\n",
    "df['length']=df['transcript'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 83])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences[31].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_batch = torch.nn.utils.rnn.pad_sequence(padded_sequences, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 83])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.to_csv(os.path.join(root_path,train_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os  \n",
    "import ast \n",
    "df=pd.read_csv(os.path.join(root_path,dev_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transcripts=df['transcript'].to_list()\n",
    "\"\"\"transcripts=[]\n",
    "for i in range(len(df)):\n",
    "    transcripts.append(ast.literal_eval(df['negative_samples'][i])[0])\"\"\"\n",
    "char_list=[]\n",
    "for trancript in transcripts:\n",
    "    char_list+=list(trancript)\n",
    "char_set=set(char_list)\n",
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list=[]\n",
    "for i in range(len(transcripts)):\n",
    "    if 'ऎ' in list(transcripts[i]):\n",
    "        idx_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21890]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([21890]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72132"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import _load_vocab\n",
    "vocab_dict=_load_vocab()\n",
    "len(vocab_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in char_set:\n",
    "    if char not in vocab_dict.keys():\n",
    "        print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ओ': 0,\n",
       " 'ज़': 1,\n",
       " 'ी': 2,\n",
       " 'छ': 3,\n",
       " 'ं': 4,\n",
       " 'ज': 5,\n",
       " 'ड': 6,\n",
       " 'ऍ': 7,\n",
       " 'ो': 8,\n",
       " 'औ': 9,\n",
       " 'ऐ': 10,\n",
       " 'घ': 11,\n",
       " 'ढ': 12,\n",
       " 'ै': 13,\n",
       " 'ठ': 14,\n",
       " 'ई': 15,\n",
       " 'ि': 16,\n",
       " 'ृ': 17,\n",
       " 'ल': 18,\n",
       " 'भ': 19,\n",
       " 'ख': 20,\n",
       " 'उ': 21,\n",
       " 'ब': 22,\n",
       " 'ग': 23,\n",
       " 'क': 24,\n",
       " 'र': 25,\n",
       " 'ू': 26,\n",
       " 'इ': 27,\n",
       " 'ॠ': 28,\n",
       " 'क़': 29,\n",
       " 'प': 30,\n",
       " 'ौ': 31,\n",
       " 'ॉ': 32,\n",
       " '़': 33,\n",
       " 'ऋ': 34,\n",
       " '|': 35,\n",
       " 'ँ': 36,\n",
       " 'ग़': 37,\n",
       " 'े': 38,\n",
       " 'फ': 39,\n",
       " 'ट': 40,\n",
       " 'त': 41,\n",
       " 'ह': 42,\n",
       " 'ः': 43,\n",
       " 'द': 44,\n",
       " 'ए': 45,\n",
       " 'ष': 46,\n",
       " 'य': 47,\n",
       " 'च': 48,\n",
       " 'व': 49,\n",
       " 'ध': 50,\n",
       " 'म': 51,\n",
       " 'थ': 52,\n",
       " 'ा': 53,\n",
       " 'ड़': 54,\n",
       " 'ऑ': 55,\n",
       " 'स': 56,\n",
       " 'ञ': 57,\n",
       " 'ढ़': 58,\n",
       " 'न': 59,\n",
       " 'ण': 60,\n",
       " 'आ': 61,\n",
       " 'झ': 62,\n",
       " 'ऊ': 63,\n",
       " '्': 64,\n",
       " 'ु': 65,\n",
       " 'फ़': 66,\n",
       " 'श': 67,\n",
       " 'अ': 68,\n",
       " 'ख़': 69,\n",
       " '1': 70,\n",
       " '5': 71,\n",
       " '2': 72,\n",
       " '8': 73,\n",
       " '3': 74,\n",
       " '6': 75,\n",
       " '7': 76,\n",
       " '0': 77,\n",
       " '9': 78,\n",
       " '4': 79,\n",
       " 'ॅ': 80,\n",
       " 'ङ': 81,\n",
       " 'य़': 82}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import _load_config\n",
    "config_file=_load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=MultiViewDevDataset(csv_file=os.path.join(root_path,dev_csv),max_mfcc_len=config_file['max_mfcc_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.max_mfcc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loader=get_dev_loader(os.path.join(root_path,dev_csv),batch_size=config_file['dev_batch_size'],max_mfcc_len=config_file['max_mfcc_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_635904/1498736576.py:274: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.nn.functional.pad(torch.tensor(seq),\n"
     ]
    }
   ],
   "source": [
    "batch=next(iter(dev_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mfcc', 'sampled_one_hot', 'lev_scores', 'ground_truth', 'one_hot_c2', 'mfcc_x2'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing MFCC lengths: 100%|██████████| 5000/5000 [02:28<00:00, 33.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MFCC length: 187\n",
      "148.38663363456726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start=time.time()\n",
    "train_data=MultiViewTrainDataset(os.path.join(root_path,train_csv),loss_fn=config_file['loss_fn'])\n",
    "end=time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.520493507385254\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "dev_data=MultiViewDevDataset(os.path.join(root_path,dev_csv))\n",
    "end=time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils import _load_config\n",
    "import json \n",
    "\n",
    "config_file=_load_config()\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "def compute_mfcc(audio_path, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        n_fft = min(2048, len(y))\n",
    "        hop_length = n_fft // 4\n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr,\n",
    "                                     n_mfcc=n_mfcc,\n",
    "                                     n_fft=n_fft,\n",
    "                                     hop_length=hop_length)\n",
    "        \n",
    "        width = min(9, mfccs.shape[1])\n",
    "        if width < 3:\n",
    "            width = 3\n",
    "        \n",
    "        width = min(width, mfccs.shape[1])\n",
    "        \n",
    "        if width % 2 == 0:\n",
    "            width -= 1\n",
    "        \n",
    "        delta1 = librosa.feature.delta(mfccs, order=1, width=width)\n",
    "        delta2 = librosa.feature.delta(mfccs, order=2, width=width)\n",
    "        \n",
    "        mfccs_combined = np.concatenate((mfccs, delta1, delta2), axis=0)\n",
    "        return mfccs_combined.shape[1]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {str(e)}\")\n",
    "        return 0    \n",
    "   \n",
    "def get_max_mfcc_length(dataset_path, n_mfcc=13, batch_size=8000,flag=\"dev\"):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    dir_path = os.path.dirname(dataset_path)\n",
    "    \n",
    "    audio_paths = [os.path.join(dir_path, str(path)) for path in df[\"audio_path\"]]\n",
    "    \n",
    "    max_len = 0\n",
    "    num_batches = len(audio_paths) // batch_size + (1 if len(audio_paths) % batch_size != 0 else 0)\n",
    "    \n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(audio_paths))\n",
    "        batch_paths = audio_paths[start_idx:end_idx]\n",
    "        \n",
    "        mfcc_length_ids = [compute_mfcc.remote(path, n_mfcc) for path in batch_paths]\n",
    "        mfcc_lengths = ray.get(mfcc_length_ids)\n",
    "        \n",
    "        batch_max = max(mfcc_lengths)\n",
    "        max_len = max(max_len, batch_max)\n",
    "    \n",
    "    print(f\"Max MFCC length: {max_len}\")\n",
    "\n",
    "    if flag==\"train\":\n",
    "        config_file[\"max_mfcc_train\"]=max_len\n",
    "    else:\n",
    "        config_file[\"max_mfcc_dev\"]=max_len\n",
    "    \n",
    "    with open(\"config.json\", 'w') as json_file:\n",
    "        json.dump(config_file, json_file,indent=4)\n",
    "\n",
    "\n",
    "    return max_len\n",
    "\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 11:24:00,652\tINFO worker.py:1762 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "Processing batches: 100%|██████████| 2/2 [00:12<00:00,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MFCC length: 194\n",
      "12.46628737449646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "max_len=get_max_mfcc_length(os.path.join(root_path,dev_csv),flag=\"dev\")\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv('/home/ubuntu/acoustic_stuff/hindi-acoustic-word-embedding/dataset/train_aligned_dataset/bhashini_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32174"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32174"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df,dev_df=train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25739"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6435"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "train_df.to_csv(os.path.join(root_path,'sample_bhashini_train.csv'))\n",
    "dev_df.to_csv(os.path.join(root_path,'sample_bhashini_dev.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR\n",
    "\n",
    "# Define the model and optimizer\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(10, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 1),\n",
    ")\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the number of warmup steps and the maximum learning rate\n",
    "warmup_steps = 100\n",
    "max_lr = 0.05\n",
    "step=0\n",
    "\n",
    "# Define the warmup scheduler\n",
    "warmup_scheduler = LinearLR(optimizer, start_factor=0.001, total_iters=warmup_steps)\n",
    "\n",
    "# Define the cosine annealing scheduler\n",
    "#cosine_scheduler = CosineAnnealingLR(optimizer, T_max=20*100-warmup_steps, eta_min=0)\n",
    "\n",
    "# Define the lambda function that returns the learning rate based on the current epoch\n",
    "def get_lr(epoch):\n",
    "    if epoch < warmup_steps:\n",
    "        return warmup_scheduler.get_lr()[0]\n",
    "    else:\n",
    "        #return cosine_scheduler.get_lr()[0]\n",
    "        pass \n",
    "\n",
    "# Define the number of epochs and the learning rate list\n",
    "num_epochs = 20\n",
    "lr_list = []\n",
    "\n",
    "# Loop over the epochs\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Update the learning rate\n",
    "    lr = get_lr(epoch)\n",
    "    lr_list.append(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    # Loop over the \"spochs\" (sub-epochs)\n",
    "    num_spochs = 100\n",
    "    for spoch in range(num_spochs):\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = torch.randn(10, 10)\n",
    "        outputs = model(inputs)\n",
    "        targets = torch.randn(10, 1)\n",
    "        loss = nn.MSELoss()(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        step+=1\n",
    "    \n",
    "    \n",
    "    #warmup_scheduler.step()\n",
    "    \n",
    "\n",
    "# Plot the learning rate using matplotlib\n",
    "plt.plot(lr_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.title('Learning rate vs. epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "class CosineScheduler:\n",
    "    def __init__(self, max_update, base_lr=0.01, final_lr=0,\n",
    "               warmup_steps=0, warmup_begin_lr=0):\n",
    "        self.base_lr_orig = base_lr\n",
    "        self.max_update = max_update\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.warmup_begin_lr = warmup_begin_lr\n",
    "        self.max_steps = self.max_update - self.warmup_steps\n",
    "\n",
    "    def get_warmup_lr(self, epoch):\n",
    "        increase = (self.base_lr_orig - self.warmup_begin_lr) \\\n",
    "                       * float(epoch) / float(self.warmup_steps)\n",
    "        return self.warmup_begin_lr + increase\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        if epoch < self.warmup_steps:\n",
    "            return self.get_warmup_lr(epoch)\n",
    "        if epoch <= self.max_update:\n",
    "            self.base_lr = self.final_lr + (\n",
    "                self.base_lr_orig - self.final_lr) * (1 + math.cos(\n",
    "                math.pi * (epoch - self.warmup_steps) / self.max_steps)) / 2\n",
    "        return self.base_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "\n",
    "import pytorch_warmup as warmup\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
